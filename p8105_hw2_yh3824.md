Homework 2
================
ruby
2025-09-26

## Problem 1

Install libraries

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

Upload and clean pols-month.csv dataset

``` r
pols_df = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon,into = c("year", "month", "day"), sep = "-", convert = TRUE) |> 
  mutate(month = month.name[month]) |> 
  pivot_longer(
    cols = starts_with("prez"),
    names_to = "president",
    values_to = "prez_values",
    names_prefix = "prez_"
    ) |>  
  filter(prez_values == "1") |> 
  select(-day, -prez_values)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

upload and clean snp.csv dataset

``` r
snp_df = 
  read_csv("fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) |>
  select(year, month, close) |> 
  mutate(month = month.name[month], 
         year = ifelse(year < 30, year + 2000, year + 1900)
         )
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

upload and clean unemployment.csv

``` r
unemploy_df = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(jan:dec, 
               names_to = "month", 
               values_to = "unemployment %") |> 
  mutate(month = month.name[match(tolower(month), tolower(month.abb))])
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
pol_combined_df =
  left_join(pols_df, snp_df, by = c("year", "month")) |> 
  left_join(unemploy_df, by = c("year", "month"))
```

### Write Up

The `pols_df`dataset contained information about the number of
democratic and republican politicians at any given time. After tidying
up the dataset, 817 observations were included with 9 variables. This
included the new `president` variable which listed if the president was
either democratic or republican at the specific month/year.

The `snp_df` dataset contained information about the S&P stock market
index. After tidying up the dataset, 787 observations were included with
3 variables.

The `unemploy_df` contained information about the percentage of
unemployment in the given month of that year. Following tidying up the
data and using a `pivot_longer` we can see that there are 816
observations and 3 variables.

Using a `left_join` we can see that the final `pol_combined_df` has 817
observations and 11 variables. The earliest year recorded is 1947 and
the most recent year recorded is 2015. Important variables in the
`pol_combined_df` include `year`, `month`, `unemployment %`, and
`close`.

## Problem 2

import and clean mr trash wheel dataset

``` r
mrtrash_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",   
             skip = 1) |> 
  janitor::clean_names() |>  
  janitor::remove_empty(which = "cols") |> 
  drop_na(dumpster) |> 
  mutate(sports_balls = as.integer(round(sports_balls)), 
         year = as.numeric(year), 
         trashwheel = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

import and clean professor trash wheel dataset

``` r
proftrash_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel", 
             skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(trashwheel = "Professor Trash Wheel")
```

import and clean gwynnda trash wheel dataset

``` r
gwynnda_df = 
  read_excel("202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel", 
             skip = 1) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(trashwheel = "Gwynns Falls Trash Wheel")
```

combine datasets

``` r
fulltrash_df = 
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df) |> 
  select(dumpster, trashwheel, everything())
```

### Write Up

The `fulltrash_df` combines the information collected in the Mr. Trash
Wheel, Professor Trash Wheel, and the Gwynn Falls trash wheel. The full
trash wheel dataset has 1188 number of observations.The total number of
variables is 15. Information about `weight_tons`, and
`volume_cubic_yards` collected in each trash wheel was reported as well
as number of plastic bottles, polystyrene, cigarette butts, glass
bottles, plastic bags, and wrappers collected at each site. Sports balls
were only collected at Mr. Trash Wheel, and not the others. The dataset
also includes information on the number of homes powered through the
trash wheels.

The total weight of trash collected by Professor Trash Wheel is 282.26
tons. The total number of cigarette butts collected by Gwynnda in June
of 2022 is 18120.

## Problem 3

import and clean zip code data

``` r
zipcode_df = 
  read_csv("zillow_data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(zip_code = as.integer(zip_code)) |> 
  select(-state_fips, - county_code, -county_fips, -file_date)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

import and clean zori data

``` r
zori_df =
  read_csv("zillow_data/Zip_Zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  mutate(zip_code = as.integer(region_name)) |> 
  pivot_longer(x2015_01_31:x2024_08_31, 
               names_to = "date", 
               values_to = "zori",
               names_prefix = "x") |> 
  separate(date, into = c("year", "month", "day"), sep = "_", convert = TRUE) |> 
  rename(county = county_name) |> 
  mutate(county = str_remove(county, 
                                  regex(" county$", ignore_case = TRUE))) |> 
  select(county, zip_code, year, month, zori) 
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

combine datasets

``` r
tidy_zillow = 
  left_join(zipcode_df, zori_df, by = c("county", "zip_code"))
```

### Write Up

In the final tidy `tidy_zillow` dataset, there was a total of 17342
observations and 6 variables. There are a total of 320 unique zip codes,
and 43 unique neighborhoods.

Which zip codes are in zipcode_df but not zori_df

``` r
zipcode_only =
  anti_join(zipcode_df, zori_df, by = "zip_code") |> 
  select(zip_code)
```

171 zip codes are in the zip code dataset, but not the zillow rental
price dataset.

This is probably because the zip code dataset includes ALL zipcodes in
New York, while the zillow dataset only includes those that have rental
properties attached to them. The zillow dataset is not the most
comprehensive reporting of all zip codes. For example, the 11430 zip
code refers to JFK airport, so it would make sense that it isn’t
included in the zillow dataset as there are no rental spaces there.
Additionally, some zip codes may be for PO boxes that are not for a home
that can be rented.

Compare rental prices in Jan 2021 to Jan 2020

``` r
rent_change = tidy_zillow  |> 
  filter(month == 1, year %in% c(2020, 2021))  |>
  select(zip_code, county, neighborhood, year, zori) |> 
  pivot_wider(
    id_cols = c(zip_code, county, neighborhood),
    names_from = year,
    values_from = zori,
    names_prefix = "rent_"
  )  |> 
  mutate(change = rent_2020 - rent_2021) |> 
  arrange(desc(change))
```

Make table with 10 largest price drops from Jan 2020 to 2021

``` r
top_10 = rent_change |> 
  slice_head(n = 10) 

top_10
```

    ## # A tibble: 10 × 6
    ##    zip_code county   neighborhood                  rent_2020 rent_2021 change
    ##       <int> <chr>    <chr>                             <dbl>     <dbl>  <dbl>
    ##  1    10007 New York Lower Manhattan                   6334.     5422.   913.
    ##  2    10069 New York <NA>                              4623.     3875.   748.
    ##  3    10009 New York Lower East Side                   3406.     2692.   714.
    ##  4    10016 New York Gramercy Park and Murray Hill     3731.     3019.   712.
    ##  5    10001 New York Chelsea and Clinton               4108.     3398.   710.
    ##  6    10002 New York Lower East Side                   3645.     2935.   710.
    ##  7    10004 New York Lower Manhattan                   3150.     2444.   706.
    ##  8    10038 New York Lower Manhattan                   3573.     2876.   698.
    ##  9    10012 New York Greenwich Village and Soho        3629.     2942.   686.
    ## 10    10010 New York Gramercy Park and Murray Hill     3697.     3012.   685.

The largest price drop from Jan 2020 to Jan 2021 is 913 in Lower
Manhattan, in the zip code 10007. The average price drop is 318. All of
the largest price drops were in New York county, 3 of which were in the
Lower Manhattan neighborhood.
